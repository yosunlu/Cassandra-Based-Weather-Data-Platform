{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "912b78f6-52ea-4212-ad73-5ad27cde1483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datacenter: datacenter1\n",
      "=======================\n",
      "Status=Up/Down\n",
      "|/ State=Normal/Leaving/Joining/Moving\n",
      "--  Address     Load        Tokens  Owns (effective)  Host ID                               Rack \n",
      "UN  172.26.0.3  317.43 KiB  16      100.0%            81b4a457-e16a-4a02-814d-f512b8a65a9d  rack1\n",
      "UN  172.26.0.2  195.74 KiB  16      100.0%            3f9ad223-fdfc-4c9b-a8cd-0750da95d497  rack1\n",
      "UN  172.26.0.4  197.6 KiB   16      100.0%            35f18065-50a7-4204-ae3c-847acea9bf88  rack1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!nodetool status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "6ef14d86-c057-4c3c-ad73-163a29064b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:cassandra.cluster:Cluster.__init__ called with contact_points specified, but no load_balancing_policy. In the next major version, this will raise an error; please specify a load-balancing policy. (contact_points = ['p6-db-1', 'p6-db-2', 'p6-db-3'], lbp = None)\n",
      "WARNING:cassandra.cluster:Downgrading core protocol version from 66 to 65 for 172.26.0.2:9042. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
      "WARNING:cassandra.cluster:Downgrading core protocol version from 65 to 5 for 172.26.0.2:9042. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n"
     ]
    }
   ],
   "source": [
    "from cassandra.cluster import Cluster\n",
    "cluster = Cluster(['p6-db-1', 'p6-db-2', 'p6-db-3'])\n",
    "cass = cluster.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "bc1d0518-7d90-4bcb-825d-2a0554d3be61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7f8893720760>"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cass.execute(\"DROP KEYSPACE IF EXISTS weather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "03c2a898-c0b5-4522-8c87-36ecf9e0f67c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7f88936e4640>"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cass.execute(\"\"\"\n",
    "CREATE KEYSPACE IF NOT EXISTS weather\n",
    "WITH REPLICATION = { \n",
    "   'class' : 'SimpleStrategy', \n",
    "   'replication_factor' : 3 \n",
    "};\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "9d7dd60c-8df2-4ff0-bf62-1a68cb67bd6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7f88b4451b40>"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cass.execute(\"USE weather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "ef173119-3d71-4386-9d7e-db969a3b05dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7f88936e4f10>"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cass.execute(\"CREATE TYPE station_record (tmin int, tmax int)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "bcf59455-ae8a-4035-a775-db1c6d11b0e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7f88bc1a5630>"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cass.execute(\"\"\"\n",
    "create table stations(\n",
    "    id TEXT,\n",
    "    name TEXT STATIC,\n",
    "    date DATE,\n",
    "    record weather.station_record,\n",
    "    PRIMARY KEY ((id), date) \n",
    ") WITH CLUSTERING ORDER BY (date ASC)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bac8e96a-23f0-490c-b0ea-4cefe40e32b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"CREATE TABLE weather.stations (\\n    id text,\\n    date date,\\n    name text static,\\n    record station_record,\\n    PRIMARY KEY (id, date)\\n) WITH CLUSTERING ORDER BY (date ASC)\\n    AND additional_write_policy = '99p'\\n    AND bloom_filter_fp_chance = 0.01\\n    AND caching = {'keys': 'ALL', 'rows_per_partition': 'NONE'}\\n    AND cdc = false\\n    AND comment = ''\\n    AND compaction = {'class': 'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy', 'max_threshold': '32', 'min_threshold': '4'}\\n    AND compression = {'chunk_length_in_kb': '16', 'class': 'org.apache.cassandra.io.compress.LZ4Compressor'}\\n    AND memtable = 'default'\\n    AND crc_check_chance = 1.0\\n    AND default_time_to_live = 0\\n    AND extensions = {}\\n    AND gc_grace_seconds = 864000\\n    AND max_index_interval = 2048\\n    AND memtable_flush_period_in_ms = 0\\n    AND min_index_interval = 128\\n    AND read_repair = 'BLOCKING'\\n    AND speculative_retry = '99p';\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q1\n",
    "#What is the Schema of stations?\n",
    "cass.execute(\"describe table weather.stations\").one().create_statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "465b1e50-9a55-403b-b0f5-1937a6f9efce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/usr/local/lib/python3.10/dist-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      "com.datastax.spark#spark-cassandra-connector_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-ed41c74d-08a0-49dd-82c1-25f34b98018a;1.0\n",
      "\tconfs: [default]\n",
      "\tfound com.datastax.spark#spark-cassandra-connector_2.12;3.4.0 in central\n",
      "\tfound com.datastax.spark#spark-cassandra-connector-driver_2.12;3.4.0 in central\n",
      "\tfound com.datastax.oss#java-driver-core-shaded;4.13.0 in central\n",
      "\tfound com.datastax.oss#native-protocol;1.5.0 in central\n",
      "\tfound com.datastax.oss#java-driver-shaded-guava;25.1-jre-graal-sub-1 in central\n",
      "\tfound com.typesafe#config;1.4.1 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.26 in central\n",
      "\tfound io.dropwizard.metrics#metrics-core;4.1.18 in central\n",
      "\tfound org.hdrhistogram#HdrHistogram;2.1.12 in central\n",
      "\tfound org.reactivestreams#reactive-streams;1.0.3 in central\n",
      "\tfound com.github.stephenc.jcip#jcip-annotations;1.0-1 in central\n",
      "\tfound com.github.spotbugs#spotbugs-annotations;3.1.12 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.2 in central\n",
      "\tfound com.datastax.oss#java-driver-mapper-runtime;4.13.0 in central\n",
      "\tfound com.datastax.oss#java-driver-query-builder;4.13.0 in central\n",
      "\tfound org.apache.commons#commons-lang3;3.10 in central\n",
      "\tfound com.thoughtworks.paranamer#paranamer;2.8 in central\n",
      "\tfound org.scala-lang#scala-reflect;2.12.11 in central\n",
      "downloading https://repo1.maven.org/maven2/com/datastax/spark/spark-cassandra-connector_2.12/3.4.0/spark-cassandra-connector_2.12-3.4.0.jar ...\n",
      "\t[SUCCESSFUL ] com.datastax.spark#spark-cassandra-connector_2.12;3.4.0!spark-cassandra-connector_2.12.jar (116ms)\n",
      "downloading https://repo1.maven.org/maven2/com/datastax/spark/spark-cassandra-connector-driver_2.12/3.4.0/spark-cassandra-connector-driver_2.12-3.4.0.jar ...\n",
      "\t[SUCCESSFUL ] com.datastax.spark#spark-cassandra-connector-driver_2.12;3.4.0!spark-cassandra-connector-driver_2.12.jar (65ms)\n",
      "downloading https://repo1.maven.org/maven2/com/datastax/oss/java-driver-core-shaded/4.13.0/java-driver-core-shaded-4.13.0.jar ...\n",
      "\t[SUCCESSFUL ] com.datastax.oss#java-driver-core-shaded;4.13.0!java-driver-core-shaded.jar (250ms)\n",
      "downloading https://repo1.maven.org/maven2/com/datastax/oss/java-driver-mapper-runtime/4.13.0/java-driver-mapper-runtime-4.13.0.jar ...\n",
      "\t[SUCCESSFUL ] com.datastax.oss#java-driver-mapper-runtime;4.13.0!java-driver-mapper-runtime.jar(bundle) (31ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/commons/commons-lang3/3.10/commons-lang3-3.10.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.commons#commons-lang3;3.10!commons-lang3.jar (53ms)\n",
      "downloading https://repo1.maven.org/maven2/com/thoughtworks/paranamer/paranamer/2.8/paranamer-2.8.jar ...\n",
      "\t[SUCCESSFUL ] com.thoughtworks.paranamer#paranamer;2.8!paranamer.jar(bundle) (33ms)\n",
      "downloading https://repo1.maven.org/maven2/org/scala-lang/scala-reflect/2.12.11/scala-reflect-2.12.11.jar ...\n",
      "\t[SUCCESSFUL ] org.scala-lang#scala-reflect;2.12.11!scala-reflect.jar (152ms)\n",
      "downloading https://repo1.maven.org/maven2/com/datastax/oss/native-protocol/1.5.0/native-protocol-1.5.0.jar ...\n",
      "\t[SUCCESSFUL ] com.datastax.oss#native-protocol;1.5.0!native-protocol.jar(bundle) (38ms)\n",
      "downloading https://repo1.maven.org/maven2/com/datastax/oss/java-driver-shaded-guava/25.1-jre-graal-sub-1/java-driver-shaded-guava-25.1-jre-graal-sub-1.jar ...\n",
      "\t[SUCCESSFUL ] com.datastax.oss#java-driver-shaded-guava;25.1-jre-graal-sub-1!java-driver-shaded-guava.jar (117ms)\n",
      "downloading https://repo1.maven.org/maven2/com/typesafe/config/1.4.1/config-1.4.1.jar ...\n",
      "\t[SUCCESSFUL ] com.typesafe#config;1.4.1!config.jar(bundle) (34ms)\n",
      "downloading https://repo1.maven.org/maven2/org/slf4j/slf4j-api/1.7.26/slf4j-api-1.7.26.jar ...\n",
      "\t[SUCCESSFUL ] org.slf4j#slf4j-api;1.7.26!slf4j-api.jar (28ms)\n",
      "downloading https://repo1.maven.org/maven2/io/dropwizard/metrics/metrics-core/4.1.18/metrics-core-4.1.18.jar ...\n",
      "\t[SUCCESSFUL ] io.dropwizard.metrics#metrics-core;4.1.18!metrics-core.jar(bundle) (30ms)\n",
      "downloading https://repo1.maven.org/maven2/org/hdrhistogram/HdrHistogram/2.1.12/HdrHistogram-2.1.12.jar ...\n",
      "\t[SUCCESSFUL ] org.hdrhistogram#HdrHistogram;2.1.12!HdrHistogram.jar(bundle) (35ms)\n",
      "downloading https://repo1.maven.org/maven2/org/reactivestreams/reactive-streams/1.0.3/reactive-streams-1.0.3.jar ...\n",
      "\t[SUCCESSFUL ] org.reactivestreams#reactive-streams;1.0.3!reactive-streams.jar (27ms)\n",
      "downloading https://repo1.maven.org/maven2/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar ...\n",
      "\t[SUCCESSFUL ] com.github.stephenc.jcip#jcip-annotations;1.0-1!jcip-annotations.jar (27ms)\n",
      "downloading https://repo1.maven.org/maven2/com/github/spotbugs/spotbugs-annotations/3.1.12/spotbugs-annotations-3.1.12.jar ...\n",
      "\t[SUCCESSFUL ] com.github.spotbugs#spotbugs-annotations;3.1.12!spotbugs-annotations.jar (28ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/code/findbugs/jsr305/3.0.2/jsr305-3.0.2.jar ...\n",
      "\t[SUCCESSFUL ] com.google.code.findbugs#jsr305;3.0.2!jsr305.jar (27ms)\n",
      "downloading https://repo1.maven.org/maven2/com/datastax/oss/java-driver-query-builder/4.13.0/java-driver-query-builder-4.13.0.jar ...\n",
      "\t[SUCCESSFUL ] com.datastax.oss#java-driver-query-builder;4.13.0!java-driver-query-builder.jar(bundle) (36ms)\n",
      ":: resolution report :: resolve 5276ms :: artifacts dl 1174ms\n",
      "\t:: modules in use:\n",
      "\tcom.datastax.oss#java-driver-core-shaded;4.13.0 from central in [default]\n",
      "\tcom.datastax.oss#java-driver-mapper-runtime;4.13.0 from central in [default]\n",
      "\tcom.datastax.oss#java-driver-query-builder;4.13.0 from central in [default]\n",
      "\tcom.datastax.oss#java-driver-shaded-guava;25.1-jre-graal-sub-1 from central in [default]\n",
      "\tcom.datastax.oss#native-protocol;1.5.0 from central in [default]\n",
      "\tcom.datastax.spark#spark-cassandra-connector-driver_2.12;3.4.0 from central in [default]\n",
      "\tcom.datastax.spark#spark-cassandra-connector_2.12;3.4.0 from central in [default]\n",
      "\tcom.github.spotbugs#spotbugs-annotations;3.1.12 from central in [default]\n",
      "\tcom.github.stephenc.jcip#jcip-annotations;1.0-1 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.2 from central in [default]\n",
      "\tcom.thoughtworks.paranamer#paranamer;2.8 from central in [default]\n",
      "\tcom.typesafe#config;1.4.1 from central in [default]\n",
      "\tio.dropwizard.metrics#metrics-core;4.1.18 from central in [default]\n",
      "\torg.apache.commons#commons-lang3;3.10 from central in [default]\n",
      "\torg.hdrhistogram#HdrHistogram;2.1.12 from central in [default]\n",
      "\torg.reactivestreams#reactive-streams;1.0.3 from central in [default]\n",
      "\torg.scala-lang#scala-reflect;2.12.11 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.26 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   18  |   18  |   18  |   0   ||   18  |   18  |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-ed41c74d-08a0-49dd-82c1-25f34b98018a\n",
      "\tconfs: [default]\n",
      "\t18 artifacts copied, 0 already retrieved (18067kB/95ms)\n",
      "23/11/16 19:50:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = (SparkSession.builder\n",
    "         .appName(\"p6\")\n",
    "         .config('spark.jars.packages', 'com.datastax.spark:spark-cassandra-connector_2.12:3.4.0')\n",
    "         .config(\"spark.sql.extensions\", \"com.datastax.spark.connector.CassandraSparkExtensions\")\n",
    "         .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "54c0f726-2e02-4c16-afe3-48d8831a81fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.text(\"ghcnd-stations.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c8f38900-be70-40e5-8fde-cca46ff77472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(value='ACW00011604  17.1167  -61.7833   10.1    ST JOHNS COOLIDGE FLD                       '),\n",
       " Row(value='ACW00011647  17.1333  -61.7833   19.2    ST JOHNS                                    '),\n",
       " Row(value='AE000041196  25.3330   55.5170   34.0    SHARJAH INTER. AIRP            GSN     41196'),\n",
       " Row(value='AEM00041194  25.2550   55.3640   10.4    DUBAI INTL                             41194'),\n",
       " Row(value='AEM00041217  24.4330   54.6510   26.8    ABU DHABI INTL                         41217'),\n",
       " Row(value='AEM00041218  24.2620   55.6090  264.9    AL AIN INTL                            41218'),\n",
       " Row(value='AF000040930  35.3170   69.0170 3366.0    NORTH-SALANG                   GSN     40930'),\n",
       " Row(value='AFM00040938  34.2100   62.2280  977.2    HERAT                                  40938'),\n",
       " Row(value='AFM00040948  34.5660   69.2120 1791.3    KABUL INTL                             40948'),\n",
       " Row(value='AFM00040990  31.5000   65.8500 1010.0    KANDAHAR AIRPORT                       40990')]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8411fd8c-1272-4ddf-9572-b0af471cd416",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, expr, rtrim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2a4974a8-b0d1-4799-9555-5051f8d963a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.withColumn(\"ID\", expr(\"substring(value, 1, 11)\")).withColumn(\"STATE\", expr(\"substring(value, 39, 2)\")).withColumn(\"NAME\", rtrim(expr(\"substring(value, 42, 30)\"))).drop(\"value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2cc9ec67-f101-4aa8-94eb-b4d5ea60544e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(ID='ACW00011604', STATE='  ', NAME='ST JOHNS COOLIDGE FLD'),\n",
       " Row(ID='ACW00011647', STATE='  ', NAME='ST JOHNS'),\n",
       " Row(ID='AE000041196', STATE='  ', NAME='SHARJAH INTER. AIRP'),\n",
       " Row(ID='AEM00041194', STATE='  ', NAME='DUBAI INTL'),\n",
       " Row(ID='AEM00041217', STATE='  ', NAME='ABU DHABI INTL'),\n",
       " Row(ID='AEM00041218', STATE='  ', NAME='AL AIN INTL'),\n",
       " Row(ID='AF000040930', STATE='  ', NAME='NORTH-SALANG'),\n",
       " Row(ID='AFM00040938', STATE='  ', NAME='HERAT'),\n",
       " Row(ID='AFM00040948', STATE='  ', NAME='KABUL INTL'),\n",
       " Row(ID='AFM00040990', STATE='  ', NAME='KANDAHAR AIRPORT')]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "842eff1a-9f20-4bad-a8cd-7c799b4d7826",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df2.write.saveAsTable(\"ID_STATE_NAME_table\", mode=\"overwrite\")\n",
    "df = spark.sql(\"\"\"\n",
    "SELECT *\n",
    "FROM ID_STATE_NAME_table\n",
    "WHERE STATE = \"WI\"\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "13ca100a-d077-4667-9d31-15e5d6523d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count = df.collect()[0]['count']\n",
    "# count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "195c8b8b-1270-4672-aa3e-05fe9ee26c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_list = df.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "ea9cd678-c4c5-4b5c-8210-c1ac37eefdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in weather_list:\n",
    "    cass.execute(\"\"\"\n",
    "        INSERT INTO stations (ID, NAME)\n",
    "        VALUES (%s, %s)\n",
    "        \"\"\",(row.ID, row.NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "712b6a7e-95d1-4f63-a396-6008c5bdaae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:cassandra.protocol:Server warning: Aggregation query used without partition key\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1313"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cass.execute(\"SELECT COUNT(*) FROM weather.stations\").one()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ac8b39c7-1c0f-4a9b-9523-71433165981a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MADISON DANE CO RGNL AP'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q2\n",
    "#What is the name corresponding to station ID USW00014837?\n",
    "cass.execute(\"\"\"\n",
    "    SELECT NAME \n",
    "    FROM weather.stations \n",
    "    WHERE ID = 'USW00014837'\n",
    "\"\"\").one()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c250cd9c-2444-4bec-a601-9402ecb2c6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#q3\n",
    "#what is the token for the USC00470273 station?\n",
    "token_0273 = cass.execute(\"\"\"\n",
    "    SELECT TOKEN(ID)\n",
    "    FROM weather.stations \n",
    "    WHERE ID = 'USW00014837'\n",
    "\"\"\").one()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1eedab28-0345-4d3b-9bf9-27728efadb18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\nDatacenter: datacenter1\\n==========\\nAddress          Rack        Status State   Load            Owns                Token                                       \\n                                                                                9159087601823522902                         \\n172.26.0.4       rack1       Up     Normal  192.43 KiB      100.00%             -8836231418056521039                        \\n172.26.0.3       rack1       Up     Normal  194.08 KiB      100.00%             -8477132856236156023                        \\n172.26.0.2       rack1       Up     Normal  194.06 KiB      100.00%             -8196359361193816454                        \\n172.26.0.3       rack1       Up     Normal  194.08 KiB      100.00%             -7659460923623805228                        \\n172.26.0.2       rack1       Up     Normal  194.06 KiB      100.00%             -7351982713702654696                        \\n172.26.0.4       rack1       Up     Normal  192.43 KiB      100.00%             -6920100163552343935                        \\n172.26.0.3       rack1       Up     Normal  194.08 KiB      100.00%             -6583705042398225688                        \\n172.26.0.4       rack1       Up     Normal  192.43 KiB      100.00%             -6174032324647428096                        \\n172.26.0.2       rack1       Up     Normal  194.06 KiB      100.00%             -5911714483800071456                        \\n172.26.0.3       rack1       Up     Normal  194.08 KiB      100.00%             -5847789349687332047                        \\n172.26.0.4       rack1       Up     Normal  192.43 KiB      100.00%             -5223791281012818115                        \\n172.26.0.2       rack1       Up     Normal  194.06 KiB      100.00%             -4840213867460038644                        \\n172.26.0.3       rack1       Up     Normal  194.08 KiB      100.00%             -4768416542239730390                        \\n172.26.0.4       rack1       Up     Normal  192.43 KiB      100.00%             -4204056237459408519                        \\n172.26.0.2       rack1       Up     Normal  194.06 KiB      100.00%             -3822362462717611628                        \\n172.26.0.3       rack1       Up     Normal  194.08 KiB      100.00%             -3524896536559138416                        \\n172.26.0.2       rack1       Up     Normal  194.06 KiB      100.00%             -3004690530105260834                        \\n172.26.0.3       rack1       Up     Normal  194.08 KiB      100.00%             -2557532293480602918                        \\n172.26.0.2       rack1       Up     Normal  194.06 KiB      100.00%             -1928934648879681294                        \\n172.26.0.4       rack1       Up     Normal  192.43 KiB      100.00%             -1495245955457340713                        \\n172.26.0.2       rack1       Up     Normal  194.06 KiB      100.00%             -1193018956168787654                        \\n172.26.0.3       rack1       Up     Normal  194.08 KiB      100.00%             -967527740966704280                         \\n172.26.0.4       rack1       Up     Normal  192.43 KiB      100.00%             -438024586690667210                         \\n172.26.0.2       rack1       Up     Normal  194.06 KiB      100.00%             -113646148721185997                         \\n172.26.0.4       rack1       Up     Normal  192.43 KiB      100.00%             358962329284396099                          \\n172.26.0.3       rack1       Up     Normal  194.08 KiB      100.00%             651495554730339016                          \\n172.26.0.2       rack1       Up     Normal  194.06 KiB      100.00%             1129873856959405975                         \\n172.26.0.3       rack1       Up     Normal  194.08 KiB      100.00%             1629641007246453092                         \\n172.26.0.2       rack1       Up     Normal  194.06 KiB      100.00%             2097238100037941474                         \\n172.26.0.4       rack1       Up     Normal  192.43 KiB      100.00%             2545076732869639646                         \\n172.26.0.4       rack1       Up     Normal  192.43 KiB      100.00%             2887443734399612232                         \\n172.26.0.3       rack1       Up     Normal  194.08 KiB      100.00%             3408275308070040220                         \\n172.26.0.2       rack1       Up     Normal  194.06 KiB      100.00%             3687242652551840112                         \\n172.26.0.4       rack1       Up     Normal  192.43 KiB      100.00%             4172345351568715193                         \\n172.26.0.3       rack1       Up     Normal  194.08 KiB      100.00%             4504317208304978509                         \\n172.26.0.4       rack1       Up     Normal  192.43 KiB      100.00%             4996215887986982353                         \\n172.26.0.2       rack1       Up     Normal  194.06 KiB      100.00%             5306265948248883409                         \\n172.26.0.3       rack1       Up     Normal  194.08 KiB      100.00%             5595614318997190768                         \\n172.26.0.4       rack1       Up     Normal  192.43 KiB      100.00%             6015737482411237822                         \\n172.26.0.2       rack1       Up     Normal  194.06 KiB      100.00%             6284411400764997485                         \\n172.26.0.3       rack1       Up     Normal  194.08 KiB      100.00%             6439990966488352526                         \\n172.26.0.4       rack1       Up     Normal  192.43 KiB      100.00%             6980391776839723544                         \\n172.26.0.4       rack1       Up     Normal  192.43 KiB      100.00%             7314801238241361129                         \\n172.26.0.3       rack1       Up     Normal  194.08 KiB      100.00%             7880259196390935764                         \\n172.26.0.2       rack1       Up     Normal  194.06 KiB      100.00%             8063045701588584613                         \\n172.26.0.4       rack1       Up     Normal  192.43 KiB      100.00%             8583927970653542623                         \\n172.26.0.3       rack1       Up     Normal  194.08 KiB      100.00%             8951759812730968577                         \\n172.26.0.2       rack1       Up     Normal  194.06 KiB      100.00%             9159087601823522902                         \\n\\n  Warning: \"nodetool ring\" is used to output all the tokens of a node.\\n  To view status related info of a node use \"nodetool status\" instead.\\n\\n\\n  '"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "output = subprocess.check_output(['nodetool', 'ring'])\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "39b7f327-8ab6-425e-8003-0701d4a262a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-8836231418056521039,\n",
       " -8477132856236156023,\n",
       " -8196359361193816454,\n",
       " -7659460923623805228,\n",
       " -7351982713702654696,\n",
       " -6920100163552343935,\n",
       " -6583705042398225688,\n",
       " -6174032324647428096,\n",
       " -5911714483800071456,\n",
       " -5847789349687332047,\n",
       " -5223791281012818115,\n",
       " -4840213867460038644,\n",
       " -4768416542239730390,\n",
       " -4204056237459408519,\n",
       " -3822362462717611628,\n",
       " -3524896536559138416,\n",
       " -3004690530105260834,\n",
       " -2557532293480602918,\n",
       " -1928934648879681294,\n",
       " -1495245955457340713,\n",
       " -1193018956168787654,\n",
       " -967527740966704280,\n",
       " -438024586690667210,\n",
       " -113646148721185997,\n",
       " 358962329284396099,\n",
       " 651495554730339016,\n",
       " 1129873856959405975,\n",
       " 1629641007246453092,\n",
       " 2097238100037941474,\n",
       " 2545076732869639646,\n",
       " 2887443734399612232,\n",
       " 3408275308070040220,\n",
       " 3687242652551840112,\n",
       " 4172345351568715193,\n",
       " 4504317208304978509,\n",
       " 4996215887986982353,\n",
       " 5306265948248883409,\n",
       " 5595614318997190768,\n",
       " 6015737482411237822,\n",
       " 6284411400764997485,\n",
       " 6439990966488352526,\n",
       " 6980391776839723544,\n",
       " 7314801238241361129,\n",
       " 7880259196390935764,\n",
       " 8063045701588584613,\n",
       " 8583927970653542623,\n",
       " 8951759812730968577,\n",
       " 9159087601823522902]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_str = output.decode('utf-8')\n",
    "lines = output_str.split('\\n')\n",
    "tokens = []\n",
    "for line in lines:\n",
    "    parts = line.split()\n",
    "    if len(parts) > 1 and parts[-1].lstrip('-').isdigit(): # without lstrip, token with leading \"-\" will be removed\n",
    "        tokens.append(int(parts[-1]))\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "96883992-0769-43e4-899d-dddf8ebe3aac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8063045701588584613"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q4\n",
    "#what is the first vnode token in the ring following the token for USC00470273?\n",
    "for i, node in enumerate(tokens):\n",
    "    if token_0273 > tokens[i] and i + 1 == len(tokens): # wrapping around\n",
    "        ans = tokens[0]\n",
    "        break\n",
    "    elif token_0273 < tokens[i+1]:\n",
    "        ans = tokens[i+1]\n",
    "        break\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ed322aa1-dd74-4716-aa63-c5011d9fc8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  records.zip\n",
      "   creating: records.parquet/\n",
      "  inflating: records.parquet/part-00000-574ab704-2431-4c8b-9d88-6c635a467b99-c000.snappy.parquet  \n",
      " extracting: records.parquet/._SUCCESS.crc  \n",
      "  inflating: records.parquet/part-00002-574ab704-2431-4c8b-9d88-6c635a467b99-c000.snappy.parquet  \n",
      "  inflating: records.parquet/part-00001-574ab704-2431-4c8b-9d88-6c635a467b99-c000.snappy.parquet  \n",
      "  inflating: records.parquet/part-00003-574ab704-2431-4c8b-9d88-6c635a467b99-c000.snappy.parquet  \n",
      " extracting: records.parquet/.part-00003-574ab704-2431-4c8b-9d88-6c635a467b99-c000.snappy.parquet.crc  \n",
      " extracting: records.parquet/_SUCCESS  \n",
      " extracting: records.parquet/.part-00000-574ab704-2431-4c8b-9d88-6c635a467b99-c000.snappy.parquet.crc  \n",
      " extracting: records.parquet/.part-00001-574ab704-2431-4c8b-9d88-6c635a467b99-c000.snappy.parquet.crc  \n",
      " extracting: records.parquet/.part-00002-574ab704-2431-4c8b-9d88-6c635a467b99-c000.snappy.parquet.crc  \n"
     ]
    }
   ],
   "source": [
    "!unzip records.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6e1f9686-51a4-40f5-931f-c3f260a7d7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_record = spark.read.parquet(\"records.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "8b7e921c-0665-493e-8079-f6e55dd7e5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "df2_record = (df_record.groupBy(\"station\", \"date\")\n",
    "                      .pivot(\"element\", [\"TMAX\",\"TMIN\"])\n",
    "                      .agg(F.first(\"value\"))\n",
    "                      .orderBy(\"station\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "07424a4b-2122-4ae0-8a4f-7cde03b1ae5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+------+\n",
      "|    station|    date|  TMAX|  TMIN|\n",
      "+-----------+--------+------+------+\n",
      "|USR0000WDDG|20220806| 317.0| 217.0|\n",
      "|USR0000WDDG|20220924| 161.0|  94.0|\n",
      "|USR0000WDDG|20220628| 283.0| 161.0|\n",
      "|USR0000WDDG|20220130| -33.0|-117.0|\n",
      "|USR0000WDDG|20220919| 278.0| 139.0|\n",
      "|USR0000WDDG|20220414|  50.0| -17.0|\n",
      "|USR0000WDDG|20220629| 306.0| 150.0|\n",
      "|USR0000WDDG|20221114|  17.0| -61.0|\n",
      "|USR0000WDDG|20220712| 289.0| 156.0|\n",
      "|USR0000WDDG|20220202|-106.0|-150.0|\n",
      "+-----------+--------+------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2_record.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f810967-7d4d-4250-ab80-17a2d4483295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cass.execute(\"\"\"\n",
    "# create table stations(\n",
    "#     id TEXT,\n",
    "#     name TEXT STATIC,\n",
    "#     date DATE,\n",
    "#     record weather.station_record,\n",
    "#     PRIMARY KEY ((id), date) \n",
    "# ) WITH CLUSTERING ORDER BY (date ASC)\n",
    "# \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "01a42841-062c-4129-bc16-93a58fcf481c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import grpc\n",
    "import station_pb2 \n",
    "import station_pb2_grpc \n",
    "\n",
    "\n",
    "rows = df2_record.collect()\n",
    "channel = grpc.insecure_channel(f\"localhost:5440\") \n",
    "stub = station_pb2_grpc.StationStub(channel)\n",
    "\n",
    "for row in rows:\n",
    "    year = row.date[:4]\n",
    "    month = row.date[4:6]\n",
    "    day = row.date[6:]    \n",
    "    request = station_pb2.RecordTempsRequest(\n",
    "        station=row.station,\n",
    "        date=str(year + \"-\" + month + \"-\" + day),\n",
    "        tmin=int(row.TMIN),\n",
    "        tmax=int(row.TMAX)\n",
    "    )\n",
    "    try:\n",
    "        response = stub.RecordTemps(request)\n",
    "        # print(response)\n",
    "    except grpc.RpcError as e:\n",
    "        print(\"gRPC call failed: {}\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "cbacb5a0-fae0-4960-900e-cb37935335e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(id='USW00014837', date=Date(18993), name='MADISON DANE CO RGNL AP', record=station_record(tmin=-99, tmax=-32))\n",
      "Row(id='USW00014837', date=Date(18994), name='MADISON DANE CO RGNL AP', record=station_record(tmin=-166, tmax=-82))\n",
      "Row(id='USW00014837', date=Date(18995), name='MADISON DANE CO RGNL AP', record=station_record(tmin=-177, tmax=-66))\n",
      "Row(id='USW00014837', date=Date(18996), name='MADISON DANE CO RGNL AP', record=station_record(tmin=-88, tmax=-5))\n",
      "Row(id='USW00014837', date=Date(18997), name='MADISON DANE CO RGNL AP', record=station_record(tmin=-116, tmax=-5))\n"
     ]
    }
   ],
   "source": [
    "result = cass.execute(\"\"\"\n",
    "SELECT *\n",
    "FROM stations\n",
    "WHERE id = 'USW00014837'\n",
    "LIMIT 5\n",
    "\"\"\")\n",
    "for row in result:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "bacaed1f-1127-49f9-ace1-5d00a508fc38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "error: \"Error from server: code=1000 [Unavailable exception] message=\\\"Cannot achieve consistency level THREE\\\" info={\\'consistency\\': \\'THREE\\', \\'required_replicas\\': 3, \\'alive_replicas\\': 2}\""
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.26.0.3:9042, scheduling retry in 27.84 seconds: [Errno 111] Tried connecting to [('172.26.0.3', 9042)]. Last error: Connection refused\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.26.0.3:9042, scheduling retry in 32.96 seconds: [Errno 111] Tried connecting to [('172.26.0.3', 9042)]. Last error: Connection refused\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.26.0.3:9042, scheduling retry in 30.72 seconds: [Errno 111] Tried connecting to [('172.26.0.3', 9042)]. Last error: Connection refused\n"
     ]
    }
   ],
   "source": [
    "#q5\n",
    "#what is the max temperature ever seen for station USW00014837?\n",
    "request = station_pb2.StationMaxRequest(station='USW00014837')\n",
    "response = stub.StationMax(request)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "07f94fd0-cec3-4548-a1a2-32dad93fcd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (spark.read.format(\"org.apache.spark.sql.cassandra\")\n",
    "      .option(\"spark.cassandra.connection.host\", \"p6-db-1,p6-db-2,p6-db-3\")\n",
    "      .option(\"keyspace\", \"weather\")\n",
    "      .option(\"table\", \"stations\")\n",
    "      .load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "d9aa4655-5764-4464-8537-4c1ba2d6d4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"stations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "16eee75c-6053-41da-a5bb-a0fbc9036b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Table(name='stations', catalog=None, namespace=[], description=None, tableType='TEMPORARY', isTemporary=True)]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q6\n",
    "#what tables/views are available in the Spark catalog?\n",
    "spark.sql(\"DROP TABLE IF EXISTS id_state_name_table\")\n",
    "spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "05f399a6-679d-45de-91d0-2474e15c3f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/17 10:35:29 WARN SimpleFunctionRegistry: The function get_tmax replaced a previously registered function.\n",
      "23/11/17 10:35:29 WARN SimpleFunctionRegistry: The function get_tmin replaced a previously registered function.\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'USW00014839': 89.6986301369863,\n",
       " 'USW00014837': 105.62739726027397,\n",
       " 'USR0000WDDG': 102.06849315068493,\n",
       " 'USW00014898': 102.93698630136986}"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/17 10:37:11 WARN ChannelPool: [s0|p6-db-2/172.26.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=bc3f6eab-0e53-4213-9f2a-176ee0fb5e72, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700164237797}): failed to send request (java.nio.channels.NotYetConnectedException))\n",
      "WARNING:cassandra.connection:Heartbeat failed for connection (140225248478160) to 172.26.0.3:9042\n",
      "WARNING:cassandra.cluster:Host 172.26.0.3:9042 has been marked down\n",
      "23/11/17 10:37:19 WARN ChannelPool: [s0|p6-db-2/172.26.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=bc3f6eab-0e53-4213-9f2a-176ee0fb5e72, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700164237797}): failed to send request (java.nio.channels.NotYetConnectedException))\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.26.0.3:9042, scheduling retry in 2.18 seconds: [Errno None] Tried connecting to [('172.26.0.3', 9042)]. Last error: timed out\n",
      "WARNING:cassandra.connection:Heartbeat failed for connection (140225248119344) to 172.26.0.3:9042\n",
      "WARNING:cassandra.cluster:Host 172.26.0.3:9042 has been marked down\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.26.0.3:9042, scheduling retry in 4.28 seconds: [Errno None] Tried connecting to [('172.26.0.3', 9042)]. Last error: timed out\n",
      "23/11/17 10:37:28 WARN ChannelPool: [s0|p6-db-2/172.26.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=bc3f6eab-0e53-4213-9f2a-176ee0fb5e72, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700164237797}): failed to send request (java.nio.channels.NotYetConnectedException))\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.26.0.3:9042, scheduling retry in 2.12 seconds: [Errno None] Tried connecting to [('172.26.0.3', 9042)]. Last error: timed out\n",
      "WARNING:cassandra.connection:Heartbeat failed for connection (140225116784192) to 172.26.0.3:9042\n",
      "WARNING:cassandra.cluster:Host 172.26.0.3:9042 has been marked down\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.26.0.3:9042, scheduling retry in 8.16 seconds: [Errno None] Tried connecting to [('172.26.0.3', 9042)]. Last error: timed out\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.26.0.3:9042, scheduling retry in 2.12 seconds: [Errno None] Tried connecting to [('172.26.0.3', 9042)]. Last error: timed out\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.26.0.3:9042, scheduling retry in 3.6 seconds: [Errno None] Tried connecting to [('172.26.0.3', 9042)]. Last error: timed out\n",
      "23/11/17 10:37:41 WARN ChannelPool: [s0|p6-db-2/172.26.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=bc3f6eab-0e53-4213-9f2a-176ee0fb5e72, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700164237797}): failed to send request (java.nio.channels.NotYetConnectedException))\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.26.0.3:9042, scheduling retry in 4.0 seconds: [Errno None] Tried connecting to [('172.26.0.3', 9042)]. Last error: timed out\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.26.0.3:9042, scheduling retry in 8.72 seconds: [Errno None] Tried connecting to [('172.26.0.3', 9042)]. Last error: timed out\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.26.0.3:9042, scheduling retry in 17.28 seconds: [Errno None] Tried connecting to [('172.26.0.3', 9042)]. Last error: timed out\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.26.0.3:9042, scheduling retry in 8.56 seconds: [Errno None] Tried connecting to [('172.26.0.3', 9042)]. Last error: timed out\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.26.0.3:9042, scheduling retry in 16.64 seconds: [Errno 113] Tried connecting to [('172.26.0.3', 9042)]. Last error: No route to host\n",
      "23/11/17 10:38:00 WARN ChannelPool: [s0|p6-db-2/172.26.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=bc3f6eab-0e53-4213-9f2a-176ee0fb5e72, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700164237797}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.26.0.3:9042, scheduling retry in 14.72 seconds: [Errno 113] Tried connecting to [('172.26.0.3', 9042)]. Last error: No route to host\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.26.0.3:9042, scheduling retry in 27.52 seconds: [Errno 113] Tried connecting to [('172.26.0.3', 9042)]. Last error: No route to host\n"
     ]
    }
   ],
   "source": [
    "#q7\n",
    "#what is the average difference between tmax and tmin, for each of the four stations that have temperature records?\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "def get_tmax(record):\n",
    "    return record.tmax if record is not None else None\n",
    "\n",
    "def get_tmin(record):\n",
    "    return record.tmin if record is not None else None\n",
    "\n",
    "get_tmax_udf = udf(get_tmax, IntegerType())\n",
    "get_tmin_udf = udf(get_tmin, IntegerType())\n",
    "\n",
    "spark.udf.register(\"get_tmax\", get_tmax_udf)\n",
    "spark.udf.register(\"get_tmin\", get_tmin_udf)\n",
    "\n",
    "diff_df = spark.sql(\"\"\"\n",
    "SELECT id, AVG(get_tmax(record) - get_tmin(record)) as diff\n",
    "FROM stations\n",
    "WHERE id = \"USW00014839\"\n",
    "OR id = \"USR0000WDDG\"\n",
    "OR id = \"USW00014837\"\n",
    "OR id = \"USW00014898\"\n",
    "GROUP BY id\n",
    "\"\"\")\n",
    "rows = diff_df.collect()\n",
    "result_dict = {row['id']: row['diff'] for row in rows}\n",
    "result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "cbdb9c9e-ce08-4b33-bdcc-9b24f9aa129b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datacenter: datacenter1\n",
      "=======================\n",
      "Status=Up/Down\n",
      "|/ State=Normal/Leaving/Joining/Moving\n",
      "--  Address     Load        Tokens  Owns (effective)  Host ID                               Rack \n",
      "UN  172.26.0.3  317.43 KiB  16      100.0%            81b4a457-e16a-4a02-814d-f512b8a65a9d  rack1\n",
      "UN  172.26.0.2  195.74 KiB  16      100.0%            3f9ad223-fdfc-4c9b-a8cd-0750da95d497  rack1\n",
      "UN  172.26.0.4  182.07 KiB  16      100.0%            35f18065-50a7-4204-ae3c-847acea9bf88  rack1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#q8\n",
    "#what does nodetool status output?\n",
    "! nodetool status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "6ae98217-f456-45bd-9c3e-8a6b3b42706d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/17 10:47:09 WARN ChannelPool: [s0|p6-db-2/172.26.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=bc3f6eab-0e53-4213-9f2a-176ee0fb5e72, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700164237797}): failed to send request (java.nio.channels.NotYetConnectedException))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "error: \"Error from server: code=1200 [Coordinator node timed out waiting for replica nodes\\' responses] message=\\\"Operation timed out - received only 2 responses.\\\" info={\\'consistency\\': \\'THREE\\', \\'required_responses\\': 3, \\'received_responses\\': 2}\""
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/17 10:47:16 WARN ChannelPool: [s0|p6-db-2/172.26.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=bc3f6eab-0e53-4213-9f2a-176ee0fb5e72, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700164237797}): failed to send request (java.nio.channels.NotYetConnectedException))\n",
      "WARNING:cassandra.cluster:Host 172.26.0.3:9042 has been marked down\n",
      "WARNING:cassandra.cluster:Host 172.26.0.3:9042 has been marked down\n",
      "23/11/17 10:47:24 WARN ChannelPool: [s0|p6-db-2/172.26.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=bc3f6eab-0e53-4213-9f2a-176ee0fb5e72, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700164237797}): failed to send request (java.nio.channels.NotYetConnectedException))\n",
      "WARNING:cassandra.connection:Heartbeat failed for connection (140224471481792) to 172.26.0.3:9042\n",
      "WARNING:cassandra.cluster:Host 172.26.0.3:9042 has been marked down\n",
      "WARNING:cassandra.connection:Heartbeat failed for connection (140224565379664) to 172.26.0.3:9042\n",
      "WARNING:cassandra.cluster:Host 172.26.0.3:9042 has been marked down\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.26.0.3:9042, scheduling retry in 2.28 seconds: [Errno None] Tried connecting to [('172.26.0.3', 9042)]. Last error: timed out\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.26.0.3:9042, scheduling retry in 2.0 seconds: [Errno None] Tried connecting to [('172.26.0.3', 9042)]. Last error: timed out\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.26.0.3:9042, scheduling retry in 2.18 seconds: [Errno None] Tried connecting to [('172.26.0.3', 9042)]. Last error: timed out\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.26.0.3:9042, scheduling retry in 1.76 seconds: [Errno None] Tried connecting to [('172.26.0.3', 9042)]. Last error: timed out\n",
      "WARNING:cassandra.connection:Heartbeat failed for connection (140224565930992) to 172.26.0.3:9042\n",
      "WARNING:cassandra.cluster:Host 172.26.0.3:9042 has been marked down\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.26.0.3:9042, scheduling retry in 3.92 seconds: [Errno 113] Tried connecting to [('172.26.0.3', 9042)]. Last error: No route to host\n",
      "23/11/17 10:47:32 WARN ChannelPool: [s0|p6-db-2/172.26.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=bc3f6eab-0e53-4213-9f2a-176ee0fb5e72, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700164237797}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.26.0.3:9042, scheduling retry in 3.8 seconds: [Errno 113] Tried connecting to [('172.26.0.3', 9042)]. Last error: No route to host\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.26.0.3:9042, scheduling retry in 2.14 seconds: [Errno 113] Tried connecting to [('172.26.0.3', 9042)]. Last error: No route to host\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.26.0.3:9042, scheduling retry in 4.56 seconds: [Errno 113] Tried connecting to [('172.26.0.3', 9042)]. Last error: No route to host\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.26.0.3:9042, scheduling retry in 4.44 seconds: [Errno 113] Tried connecting to [('172.26.0.3', 9042)]. Last error: No route to host\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.26.0.3:9042, scheduling retry in 7.6 seconds: [Errno 113] Tried connecting to [('172.26.0.3', 9042)]. Last error: No route to host\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.26.0.3:9042, scheduling retry in 8.4 seconds: [Errno 113] Tried connecting to [('172.26.0.3', 9042)]. Last error: No route to host\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.26.0.3:9042, scheduling retry in 3.96 seconds: [Errno 113] Tried connecting to [('172.26.0.3', 9042)]. Last error: No route to host\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.26.0.3:9042, scheduling retry in 7.36 seconds: [Errno 113] Tried connecting to [('172.26.0.3', 9042)]. Last error: No route to host\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.26.0.3:9042, scheduling retry in 7.12 seconds: [Errno 113] Tried connecting to [('172.26.0.3', 9042)]. Last error: No route to host\n",
      "WARNING:cassandra.connection:Heartbeat failed for connection (140224414993952) to 172.26.0.3:9042\n",
      "WARNING:cassandra.cluster:Host 172.26.0.3:9042 has been marked down\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.26.0.3:9042, scheduling retry in 9.04 seconds: [Errno 113] Tried connecting to [('172.26.0.3', 9042)]. Last error: No route to host\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.26.0.3:9042, scheduling retry in 1.7 seconds: [Errno 113] Tried connecting to [('172.26.0.3', 9042)]. Last error: No route to host\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.26.0.3:9042, scheduling retry in 15.2 seconds: [Errno 113] Tried connecting to [('172.26.0.3', 9042)]. Last error: No route to host\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.26.0.3:9042, scheduling retry in 18.08 seconds: [Errno 113] Tried connecting to [('172.26.0.3', 9042)]. Last error: No route to host\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.26.0.3:9042, scheduling retry in 18.24 seconds: [Errno 113] Tried connecting to [('172.26.0.3', 9042)]. Last error: No route to host\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.26.0.3:9042, scheduling retry in 15.04 seconds: [Errno 113] Tried connecting to [('172.26.0.3', 9042)]. Last error: No route to host\n",
      "23/11/17 10:47:51 WARN ChannelPool: [s0|p6-db-2/172.26.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=bc3f6eab-0e53-4213-9f2a-176ee0fb5e72, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700164237797}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.26.0.3:9042, scheduling retry in 3.76 seconds: [Errno 113] Tried connecting to [('172.26.0.3', 9042)]. Last error: No route to host\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.26.0.3:9042, scheduling retry in 15.36 seconds: [Errno 113] Tried connecting to [('172.26.0.3', 9042)]. Last error: No route to host\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.26.0.3:9042, scheduling retry in 8.8 seconds: [Errno 113] Tried connecting to [('172.26.0.3', 9042)]. Last error: No route to host\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.26.0.3:9042, scheduling retry in 31.68 seconds: [Errno 113] Tried connecting to [('172.26.0.3', 9042)]. Last error: No route to host\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.26.0.3:9042, scheduling retry in 31.04 seconds: [Errno 113] Tried connecting to [('172.26.0.3', 9042)]. Last error: No route to host\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.26.0.3:9042, scheduling retry in 16.16 seconds: [Errno 113] Tried connecting to [('172.26.0.3', 9042)]. Last error: No route to host\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.26.0.3:9042, scheduling retry in 36.48 seconds: [Errno 113] Tried connecting to [('172.26.0.3', 9042)]. Last error: No route to host\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.26.0.3:9042, scheduling retry in 28.16 seconds: [Errno 113] Tried connecting to [('172.26.0.3', 9042)]. Last error: No route to host\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.26.0.3:9042, scheduling retry in 32.0 seconds: [Errno 113] Tried connecting to [('172.26.0.3', 9042)]. Last error: No route to host\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.26.0.3:9042, scheduling retry in 29.76 seconds: [Errno 113] Tried connecting to [('172.26.0.3', 9042)]. Last error: No route to host\n",
      "23/11/17 10:48:26 WARN ChannelPool: [s0|p6-db-2/172.26.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=bc3f6eab-0e53-4213-9f2a-176ee0fb5e72, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700164237797}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.26.0.3:9042, scheduling retry in 66.56 seconds: [Errno 113] Tried connecting to [('172.26.0.3', 9042)]. Last error: No route to host\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.26.0.3:9042, scheduling retry in 67.2 seconds: [Errno 113] Tried connecting to [('172.26.0.3', 9042)]. Last error: No route to host\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.26.0.3:9042, scheduling retry in 71.68 seconds: [Errno 113] Tried connecting to [('172.26.0.3', 9042)]. Last error: No route to host\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.26.0.3:9042, scheduling retry in 71.68 seconds: [Errno 113] Tried connecting to [('172.26.0.3', 9042)]. Last error: No route to host\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.26.0.3:9042, scheduling retry in 63.36 seconds: [Errno 113] Tried connecting to [('172.26.0.3', 9042)]. Last error: No route to host\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.26.0.3:9042, scheduling retry in 61.44 seconds: [Errno 113] Tried connecting to [('172.26.0.3', 9042)]. Last error: No route to host\n",
      "23/11/17 10:49:26 WARN ChannelPool: [s0|p6-db-2/172.26.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=bc3f6eab-0e53-4213-9f2a-176ee0fb5e72, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700164237797}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.26.0.3:9042, scheduling retry in 130.56 seconds: [Errno 113] Tried connecting to [('172.26.0.3', 9042)]. Last error: No route to host\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.26.0.3:9042, scheduling retry in 129.28 seconds: [Errno 113] Tried connecting to [('172.26.0.3', 9042)]. Last error: No route to host\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.26.0.3:9042, scheduling retry in 143.36 seconds: [Errno 113] Tried connecting to [('172.26.0.3', 9042)]. Last error: No route to host\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.26.0.3:9042, scheduling retry in 131.84 seconds: [Errno 113] Tried connecting to [('172.26.0.3', 9042)]. Last error: No route to host\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.26.0.3:9042, scheduling retry in 139.52 seconds: [Errno 113] Tried connecting to [('172.26.0.3', 9042)]. Last error: No route to host\n"
     ]
    }
   ],
   "source": [
    "#q9\n",
    "#if you make a StationMax RPC call, what does the error field contain in StationMaxReply reply?\n",
    "request = station_pb2.StationMaxRequest(station='USW00014837')\n",
    "response = stub.StationMax(request)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "2592f7d9-41e6-4ef9-8dac-6c51214b1673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.26.0.3:9042, scheduling retry in 134.4 seconds: [Errno 113] Tried connecting to [('172.26.0.3', 9042)]. Last error: No route to host\n",
      "23/11/17 10:50:28 WARN ChannelPool: [s0|p6-db-2/172.26.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=bc3f6eab-0e53-4213-9f2a-176ee0fb5e72, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700164237797}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n"
     ]
    }
   ],
   "source": [
    "#q10\n",
    "#if you make a RecordTempsRequest RPC call, what does error contain in the RecordTempsReply reply?\n",
    "request = station_pb2.RecordTempsRequest(\n",
    "    station=\"UWMADISON\",\n",
    "    date=str(\"2023-4-20\"),\n",
    "    tmin=int(0),\n",
    "    tmax=int(100)\n",
    ")\n",
    "\n",
    "response = stub.RecordTemps(request)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff6ced5-8d84-46fb-a52f-a5a84fa553b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
